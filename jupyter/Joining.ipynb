{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5215439a",
   "metadata": {},
   "source": [
    "# Integración de datasets de correos electrónicos (Nazario, Nigerian Fraud y SpamAssassin)\n",
    "\n",
    "En este notebook realizamos la primera etapa del proyecto: **integrar y explorar tres fuentes distintas de correos electrónicos** (Nazario, Nigerian Fraud y SpamAssassin) para construir un solo dataset unificado que usaremos en el resto del análisis y modelado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b98790",
   "metadata": {},
   "source": [
    "## 1. Carga de librerías y datasets originales\n",
    "\n",
    "En esta sección:\n",
    "\n",
    "- Importamos la librería **pandas**, que usaremos para manipulación de datos en formato tabular.\n",
    "- Cargamos los tres archivos CSV que contienen los correos electrónicos:\n",
    "  - `Nazario.csv`: correos catalogados como phishing.\n",
    "  - `Nigerian_Fraud.csv`: corpus de correos de fraude tipo “Nigerian scam”.\n",
    "  - `SpamAssasin.csv`: corpus público con correos spam y legítimos.\n",
    "\n",
    "Cada uno se carga en un `DataFrame` de pandas para poder trabajarlos de forma estructurada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e5d805a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librerias, pandas para manejo de datos\n",
    "import pandas as pd\n",
    "\n",
    "#Importamos los datasets originales\n",
    "naz = pd.read_csv(\"Nazario.csv\")\n",
    "nig = pd.read_csv(\"Nigerian_Fraud.csv\")\n",
    "spa = pd.read_csv(\"SpamAssasin.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54aad15e",
   "metadata": {},
   "source": [
    "## 2. Integración de los tres datasets en un solo DataFrame\n",
    "\n",
    "Para poder rastrear de dónde viene cada correo electrónico dentro del dataset integrado:\n",
    "\n",
    "- Agregamos una columna llamada `origen` a cada `DataFrame`, con el nombre del dataset de procedencia.\n",
    "- Después, **concatenamos** los tres `DataFrames` verticalmente usando `pd.concat`, creando un solo dataset llamado `data`.\n",
    "\n",
    "De esta forma, cada fila del dataset final conserva el contexto de si proviene de Nazario, Nigerian Fraud o SpamAssassin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e01915f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agregamos una columna de origen, para determinar de qué dataset viene la info\n",
    "naz['origen'] = 'Nazario'\n",
    "nig['origen'] = 'Nigerian_Fraud'\n",
    "spa['origen'] = 'SpamAssasin'\n",
    "\n",
    "#Unimos los datasets en uno solo\n",
    "data = pd.concat([naz, nig, spa], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a582849",
   "metadata": {},
   "source": [
    "## 3. Chequeo inicial de calidad de datos\n",
    "\n",
    "Antes de seguir con el preprocesamiento es importante revisar:\n",
    "\n",
    "- **Distribución de la variable objetivo (`label`)**  \n",
    "  Esto nos indica cuántos correos están etiquetados como phishing/spam (1) y cuántos como legítimos (0). Nos sirve para detectar desbalance de clases.\n",
    "\n",
    "- **Duplicados por cuerpo (`body`)**  \n",
    "  Contamos cuántos correos tienen exactamente el mismo texto en el cuerpo. Esto puede indicar correos repetidos entre datasets o dentro de un mismo corpus.\n",
    "\n",
    "- **Porcentaje de valores faltantes (`NaN`) por columna**  \n",
    "  Calculamos el promedio de valores faltantes por campo para entender qué tan incompletas están columnas como `sender`, `receiver`, `date` o `subject`.  \n",
    "  Esta información será la base para definir las estrategias de limpieza posteriores (imputación, eliminación, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27040537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribución de clases en el dataset combinado: \n",
      "label\n",
      "1    6615\n",
      "0    4091\n",
      "Name: count, dtype: int64\n",
      "Duplicados por body: 2\n",
      "Valores faltantes:\n",
      "sender      0.031\n",
      "receiver    0.152\n",
      "date        0.045\n",
      "subject     0.006\n",
      "body        0.000\n",
      "urls        0.000\n",
      "label       0.000\n",
      "origen      0.000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#verificamos el balance de clases\n",
    "print(\"Distribución de clases en el dataset combinado: \")\n",
    "print(data['label'].value_counts())\n",
    "\n",
    "#Verificar duplicados y valores faltantes\n",
    "print(\"Duplicados por body:\", data.duplicated(subset=[\"body\"]).sum())\n",
    "print(\"Valores faltantes:\")\n",
    "print(data.isna().mean().round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba5ac5a",
   "metadata": {},
   "source": [
    "## 4. Exportación del dataset integrado\n",
    "\n",
    "Finalmente, guardamos el `DataFrame` resultante en un archivo llamado **`Combined_Dataset.csv`**.\n",
    "\n",
    "Este archivo representa el **dataset unificado** que concentra:\n",
    "\n",
    "- Los correos de Nazario,\n",
    "- Los correos de Nigerian Fraud,\n",
    "- Los correos de SpamAssassin,\n",
    "\n",
    "junto con la columna `origen` y las etiquetas `label`.  \n",
    "\n",
    "Este CSV será el punto de partida para:\n",
    "- El **EDA en Python y Excel**,\n",
    "- La **ingeniería de características**, \n",
    "- El **entrenamiento de modelos de clasificación** en Python y Orange,\n",
    "- Y la alimentación de las herramientas de visualización (Power BI / Looker Studio)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07b33b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardamos el dataset combinado en un nuevo archivo CSV\n",
    "data.to_csv(\"Combined_Dataset.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
